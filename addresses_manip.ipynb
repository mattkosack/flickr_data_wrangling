{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: write markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv, itertools, os, json, traceback\n",
    "import datetime\n",
    "import dotenv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from geopy.geocoders import Nominatim\n",
    "from geopy.extra.rate_limiter import RateLimiter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dotenv\n",
    "dotenv.load_dotenv()\n",
    "PROJECT_DIR = os.getenv('PROJECT_DIR')\n",
    "\n",
    "# Go to proper dir\n",
    "os.chdir(PROJECT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gps_coords_one_line(json_entry):\n",
    "    # Use GPS co-ords to process the postal address later\n",
    "    latitude = json_entry['Latitude']\n",
    "    longitude = json_entry['Longitude']\n",
    "\n",
    "    return {\n",
    "        'latitude': latitude, \n",
    "        'longitude': longitude\n",
    "    }\n",
    "\n",
    "\n",
    "def get_datetime_info_one_line(json_entry):\n",
    "    # Process the datetimes of the image\n",
    "    # Not all will have values for either value\n",
    "    # Timezone causes failure and dont have time to process in multiple formats to replace before strip\n",
    "    # print(json_entry)\n",
    "    # exit()\n",
    "    try:\n",
    "        dto = datetime.datetime.strptime(json_entry['EXIF:DateTimeOriginal'], '%Y:%m:%d %H:%M:%S')\n",
    "    except KeyError as e:\n",
    "        dto = None\n",
    "    except ValueError as e:\n",
    "        dto = None\n",
    "\n",
    "    try:\n",
    "        mod_date = datetime.datetime.strptime(json_entry['EXIF:ModifyDate'], '%Y:%m:%d %H:%M:%S')\n",
    "    except KeyError as e:\n",
    "        mod_date = None\n",
    "    except ValueError as e:\n",
    "        mod_date = None\n",
    "\n",
    "    # Process the time between when image was captured and when image was last modified\n",
    "    # Might need to test this\n",
    "    # print(dto)\n",
    "    if dto is not None and mod_date is not None:\n",
    "        time_delta = mod_date - dto\n",
    "    else:\n",
    "        time_delta = None\n",
    "    \n",
    "    return {\n",
    "        'date_time_original': dto, \n",
    "        'modified_date': mod_date, \n",
    "        'time_delta': time_delta\n",
    "    }\n",
    "\n",
    "\n",
    "def get_camera_info_one_line(json_entry):\n",
    "    #\n",
    "    try:\n",
    "        camera_make = json_entry['EXIF:Make']\n",
    "    except KeyError as e:\n",
    "        camera_make = None\n",
    "    try:\n",
    "        camera_model = json_entry['EXIF:Model']\n",
    "    except KeyError as e:\n",
    "        camera_model = None\n",
    "    try:\n",
    "        software = json_entry['EXIF:Software']\n",
    "    except KeyError as e:\n",
    "        software = None\n",
    "    try:\n",
    "        shutter_speed = json_entry['EXIF:ShutterSpeedValue']\n",
    "    except KeyError as e:\n",
    "        shutter_speed = None\n",
    "    try:\n",
    "        flash = json_entry['EXIF:Flash']\n",
    "    except KeyError as e:\n",
    "        flash = None\n",
    "    try:\n",
    "        focal_length = json_entry['EXIF:FocalLength']\n",
    "    except KeyError as e:\n",
    "        focal_length = None\n",
    "    try:\n",
    "        lens_model = json_entry['EXIF:LensModel']\n",
    "    except KeyError as e:\n",
    "        lens_model = None\n",
    "    \n",
    "    return {\n",
    "        'camera_make': camera_make,\n",
    "        'camera_model': camera_model, \n",
    "        'software': software,\n",
    "        'shutter_speed': shutter_speed, \n",
    "        'flash': flash, \n",
    "        'focal_length': focal_length, \n",
    "        'lens_model': lens_model\n",
    "    }\n",
    "\n",
    "\n",
    "def get_data_one_line(json_entry):\n",
    "    # Identifies an image more accurately than the filename across different files\n",
    "    data = {'image_id': json_entry['Image_ID']}\n",
    "    # latitude, longitude = get_gps_coords_one_line(json_entry)\n",
    "    data.update(get_gps_coords_one_line(json_entry))\n",
    "    data.update(get_datetime_info_one_line(json_entry))\n",
    "    # date_time_origial, mod_date, time_delta = get_datetime_info_one_line(json_entry)\n",
    "    data.update(get_camera_info_one_line(json_entry))\n",
    "    return data\n",
    "\n",
    "\n",
    "def get_data(INFILE):\n",
    "    data = []\n",
    "    with open(INFILE, 'r') as in_file:\n",
    "        rows = json.load(in_file)\n",
    "        for row in rows:\n",
    "            data.append(get_data_one_line(row))\n",
    "    return data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Geolocator stuff\n",
    "geolocator = Nominatim(user_agent=\"test_app\")\n",
    "geocode = RateLimiter(geolocator.geocode, min_delay_seconds=1) # Delay needed or else will run into problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "INFILE = f'{PROJECT_DIR}/exif_data/exif_data.json'\n",
    "OUTFILE_ADDRESSES = './output_addresses.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTFILE_CAMERA_INFO = f'{PROJECT_DIR}/output_camera_info.csv'\n",
    "OUTFILE_DATETIME_INFO = f'{PROJECT_DIR}/output_datetime_info.csv'\n",
    "camera_info_headers = ['image_id', 'camera_make', 'camera_model', 'software', 'shutter_speed', 'flash', \n",
    "                       'focal_length', 'lens_model']\n",
    "datetime_info_headers = ['image_id', 'date_time_original', 'modified_date', 'time_delta']\n",
    "\n",
    "def write_camera_data(data):\n",
    "    if os.path.isfile(OUTFILE_CAMERA_INFO):\n",
    "        read_mode = 'a'\n",
    "    else:\n",
    "        read_mode = 'w'\n",
    "\n",
    "    with open(OUTFILE_CAMERA_INFO, read_mode) as out_file:\n",
    "        writer = csv.writer(out_file)\n",
    "        if read_mode == 'w':\n",
    "            writer.writerow(camera_info_headers)\n",
    "            \n",
    "        for entry in data:\n",
    "            values = [entry.get(header) for header in camera_info_headers]\n",
    "            writer.writerow(values)\n",
    "\n",
    "\n",
    "def write_datetime_data(data):\n",
    "    if os.path.isfile(OUTFILE_DATETIME_INFO):\n",
    "        read_mode = 'a'\n",
    "    else:\n",
    "        read_mode = 'w'\n",
    "\n",
    "    with open(OUTFILE_DATETIME_INFO, read_mode) as out_file:\n",
    "        writer = csv.writer(out_file)\n",
    "        if read_mode == 'w':\n",
    "            writer.writerow(datetime_info_headers)\n",
    "            \n",
    "        for entry in data:\n",
    "            values = [entry.get(header) for header in datetime_info_headers]\n",
    "            writer.writerow(values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_data(INFILE)\n",
    "write_camera_data(data)\n",
    "write_datetime_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates_data = pd.read_csv(OUTFILE_DATETIME_INFO)\n",
    "# print(dates_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_data = pd.read_csv(OUTFILE_CAMERA_INFO)\n",
    "# print(camera_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_headers = ['amenity', 'building', 'tourism', 'place', 'house_number', 'emergency', 'leisure', 'quarter',\n",
    "              'highway', 'historic', 'man_made', 'natural', 'road', 'farm', 'isolated_dwelling', 'neighbourhood', \n",
    "              'residential', 'suburb', 'city_district', 'town', 'locality', 'city', 'hamlet', 'village', \n",
    "              'municipality', 'county', 'state_district', 'district', 'province', 'state', 'region', 'postcode', 'country', \n",
    "              'country_code']\n",
    "empty_address_dict = {}\n",
    "for key in csv_headers:\n",
    "    empty_address_dict[key] = None\n",
    "\n",
    "illegal_country_codes = ['eg'] # Arabic scripts not supported\n",
    "# missing_from_illegal_country_codes = []\n",
    "\n",
    "# TODO: test this still works with a SMALLER file. the 1000 lie one takes about 10 mins\n",
    "def write_address_data(data):\n",
    "    ctr = 0\n",
    "    if os.path.isfile(OUTFILE_ADDRESSES):\n",
    "        read_mode = 'w'\n",
    "    else:\n",
    "        read_mode = 'a'\n",
    "\n",
    "    with open(OUTFILE_ADDRESSES, read_mode) as out_file:\n",
    "        writer = csv.writer(out_file)\n",
    "        if read_mode == 'w':\n",
    "            header_row = itertools.chain(['image_id'], csv_headers)\n",
    "            writer.writerow(header_row)\n",
    "\n",
    "        for row in data:\n",
    "            img_id = row['image_id']\n",
    "            try: \n",
    "                # This is where most of the time running this will be taken\n",
    "                address_data = geolocator.reverse((row['latitude'], row['longitude'])).raw['address']\n",
    "                this_address_dict = empty_address_dict.copy()\n",
    "                # Some images don't have country codes\n",
    "                try:\n",
    "                    country_code = address_data['country_code']\n",
    "                except KeyError as key_exc:\n",
    "                    country_code = None\n",
    "\n",
    "                if country_code not in illegal_country_codes:\n",
    "                    # There's probably a better way to do this, but I don't care\n",
    "                    for key, value in address_data.items():\n",
    "                        this_address_dict[key] = value\n",
    "                    out_row = itertools.chain(img_id, this_address_dict.values())\n",
    "                    print(f\"Wrote row img {img_id} to #{ctr}\")\n",
    "                    writer.writerow(out_row)\n",
    "                else:\n",
    "                    print(f'Skipping write for image with id,country code {img_id},{country_code}')\n",
    "                    # missing_from_illegal_country_codes.append(img_id)\n",
    "            except Exception as e:\n",
    "                print(f'Write failed for image with id {img_id}')\n",
    "\n",
    "            ctr+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote row img 27653319031 to #0\n",
      "Wrote row img 22697429926 to #1\n",
      "Wrote row img 6650348617 to #2\n",
      "Wrote row img 12337695235 to #3\n",
      "Wrote row img 8432503596 to #4\n",
      "Wrote row img 15629040035 to #5\n",
      "Wrote row img 20610126982 to #6\n",
      "Wrote row img 29359326241 to #7\n",
      "Wrote row img 14095127199 to #8\n",
      "Wrote row img 6219236142 to #9\n",
      "Wrote row img 8310392852 to #10\n",
      "Wrote row img 23313968663 to #11\n",
      "Wrote row img 9534473273 to #12\n",
      "Wrote row img 14086415848 to #13\n",
      "Wrote row img 5669373138 to #14\n",
      "Wrote row img 27534225480 to #15\n",
      "Wrote row img 10486187245 to #16\n",
      "Wrote row img 14191645299 to #17\n",
      "Wrote row img 9587382078 to #18\n",
      "Wrote row img 15035657071 to #19\n",
      "Wrote row img 4335488443 to #20\n",
      "Wrote row img 3888632330 to #21\n",
      "Wrote row img 13844211075 to #22\n",
      "Wrote row img 14124294348 to #23\n",
      "Wrote row img 15720949851 to #24\n",
      "Wrote row img 6132942800 to #25\n",
      "Wrote row img 20067543468 to #26\n",
      "Wrote row img 28069344081 to #27\n",
      "Wrote row img 28168408525 to #28\n",
      "Wrote row img 6357276861 to #29\n",
      "Wrote row img 44645439685 to #30\n",
      "Wrote row img 12099100483 to #31\n",
      "Wrote row img 12922790264 to #32\n",
      "Wrote row img 5013180852 to #33\n",
      "Wrote row img 3391069291 to #34\n",
      "Wrote row img 6207108714 to #35\n",
      "Wrote row img 15621924802 to #36\n",
      "Wrote row img 26690235425 to #37\n",
      "Wrote row img 7424031778 to #38\n",
      "Wrote row img 14496148339 to #39\n",
      "Wrote row img 29873646765 to #40\n",
      "Wrote row img 11681447725 to #41\n",
      "Wrote row img 6350021370 to #42\n",
      "Wrote row img 9112301403 to #43\n",
      "Wrote row img 6699825585 to #44\n",
      "Wrote row img 28859007296 to #45\n",
      "Wrote row img 12099446786 to #46\n",
      "Wrote row img 13348143404 to #47\n",
      "Wrote row img 19996441434 to #48\n",
      "Wrote row img 12912675924 to #49\n",
      "Wrote row img 20181914739 to #50\n",
      "Wrote row img 4693296436 to #51\n",
      "Wrote row img 5814228991 to #52\n",
      "Wrote row img 27347901735 to #53\n",
      "Wrote row img 6243337623 to #54\n",
      "Wrote row img 6984241055 to #55\n",
      "Wrote row img 35172729441 to #56\n",
      "Wrote row img 6233933932 to #57\n",
      "Wrote row img 21033097545 to #58\n",
      "Wrote row img 19450426369 to #59\n",
      "Wrote row img 15142221196 to #60\n",
      "Wrote row img 33865932575 to #61\n",
      "Wrote row img 6225895624 to #62\n",
      "Wrote row img 2647408576 to #63\n",
      "Wrote row img 5984270138 to #64\n",
      "Wrote row img 28562052230 to #65\n",
      "Wrote row img 36946659120 to #66\n",
      "Wrote row img 14029339573 to #67\n",
      "Wrote row img 10462415125 to #68\n",
      "Wrote row img 23251917722 to #69\n",
      "Wrote row img 15427881539 to #70\n",
      "Wrote row img 4507059471 to #71\n",
      "Wrote row img 6908478597 to #72\n",
      "Wrote row img 27448330960 to #73\n",
      "Wrote row img 14446676900 to #74\n",
      "Wrote row img 3909300346 to #75\n",
      "Wrote row img 6362150571 to #76\n",
      "Wrote row img 28534660022 to #77\n",
      "Wrote row img 5926314392 to #78\n",
      "Wrote row img 22552437982 to #79\n",
      "Wrote row img 16068020762 to #80\n",
      "Wrote row img 9321294269 to #81\n",
      "Wrote row img 34479822011 to #82\n",
      "Wrote row img 6825023424 to #83\n",
      "Wrote row img 9220211179 to #84\n",
      "Wrote row img 5270765382 to #85\n",
      "Wrote row img 4375353644 to #86\n",
      "Wrote row img 3410299132 to #87\n",
      "Wrote row img 19968945094 to #88\n",
      "Wrote row img 11598086723 to #89\n",
      "Wrote row img 14978529209 to #90\n",
      "Wrote row img 10531365366 to #91\n",
      "Wrote row img 15307353777 to #92\n",
      "Wrote row img 14287783122 to #93\n",
      "Wrote row img 5356186293 to #94\n",
      "Wrote row img 3833385282 to #95\n",
      "Wrote row img 8813969257 to #96\n",
      "Wrote row img 14364321954 to #97\n",
      "Wrote row img 16527303765 to #98\n"
     ]
    }
   ],
   "source": [
    "# TODO: test this, see above\n",
    "write_address_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here are all the unique keys from geolocator.reverse(s).raw:\n",
    "#\n",
    "# place_id\n",
    "# licence\n",
    "# osm_type\n",
    "# osm_id\n",
    "# lat\n",
    "# lon\n",
    "# display_name\n",
    "# address\n",
    "# boundingbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: once the write_address_data func is tested, this cell can be deleted\n",
    "\n",
    "# illegal_country_codes = ['eg']\n",
    "# missing_from_illegal_country_codes = []\n",
    "# # TODO make this conditional on file existing\n",
    "# if True:\n",
    "#     mode = 'w'\n",
    "\n",
    "# EXIF_DATA_FILE = f'{PROJECT_DIR}/exif_data/exif_data_11_29_first_1000.json'\n",
    "# OUTPUT_FILE = f'{PROJECT_DIR}/output.csv'\n",
    "# ctr = 0\n",
    "# with open(EXIF_DATA_FILE, 'r') as in_file:\n",
    "#     with open(OUTPUT_FILE, mode) as out_file:\n",
    "#         writer = csv.writer(out_file)\n",
    "#         if mode == 'w':\n",
    "#                 header_row = itertools.chain(['image_id'], csv_headers)\n",
    "#                 writer.writerow(header_row)  \n",
    "\n",
    "#         rows = json.load(in_file)\n",
    "#         for row in rows:\n",
    "            \n",
    "#             img_id = row['Image_ID']\n",
    "#             latitude = row['Latitude']\n",
    "#             longitude = row['Longitude']\n",
    "              \n",
    "#             try:\n",
    "#                 address_data = geolocator.reverse((latitude, longitude)).raw['address']\n",
    "#                 this_address_dict = address_dict.copy()\n",
    "#                 # Some images don't have country codes\n",
    "#                 try:\n",
    "#                     country_code = address_data['country_code']\n",
    "#                 except KeyError as key_exc:\n",
    "#                     country_code = None\n",
    "\n",
    "#                 if country_code not in illegal_country_codes:\n",
    "#                     # There's probably a better way to do this, but I don't care\n",
    "#                     for key, value in address_data.items():\n",
    "#                         this_address_dict[key] = value\n",
    "#                     out_row = itertools.chain([img_id], this_address_dict.values())\n",
    "#                     print(f\"Wrote row img {img_id} to #{ctr}\")\n",
    "#                     writer.writerow(out_row)\n",
    "#                 else:\n",
    "#                     print(f'Skipping write for image with id,country code {img_id},{country_code}')\n",
    "#                     missing_from_illegal_country_codes.append(img_id)\n",
    "#             except Exception as e:\n",
    "#                 print(f'Write failed for image with id {img_id}')\n",
    "#                 # traceback.print_exc()\n",
    "#                 # exit()\n",
    "\n",
    "#             ctr+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT DELETE THIS\n",
    "\n",
    "# amenity\n",
    "# building\n",
    "# tourism\n",
    "# place (before house_number)\n",
    "# house_number\n",
    "# emergency, leisure\n",
    "# quarter\n",
    "# man_made, highway, historic, natural (only indication is before road)\n",
    "# highway (only indicatio is before road)\n",
    "# natural (only indicator is before road)\n",
    "# historic comes before road\n",
    "# road\n",
    "# farm (after road, before city_district)\n",
    "# isolated_dwelling (between road and city)\n",
    "# neighbourhood\n",
    "# residential (before suburb)\n",
    "# suburb\n",
    "# city_district (before town, after suburb)\n",
    "# town\n",
    "# locality\n",
    "# city\n",
    "# hamlet\n",
    "# village (sometimes before city, sometimes after)\n",
    "# municipality\n",
    "# county\n",
    "# state_district\n",
    "# province (before state or region)\n",
    "# state\n",
    "# region (after state_district, state - before postcode)\n",
    "# postcode\n",
    "# country\n",
    "# # country_code\n",
    "\n",
    "# csv_headers = ['amenity', 'building', 'tourism', 'place', 'house_number', 'emergency', 'leisure', 'quarter',\n",
    "#               'highway', 'historic', 'man_made', 'natural', 'road', 'farm', 'isolated_dwelling', 'neighbourhood', \n",
    "#               'residential', 'suburb', 'city_district', 'town', 'locality', 'city', 'hamlet', 'village', \n",
    "#               'municipality', 'county', 'state_district', 'district', 'province', 'state', 'region', 'postcode', 'country', \n",
    "#               'country_code']"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
